{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mount GDrive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # os.chdir allows you to change directories, like cd in the Terminal\n",
    "# os.chdir('/content/drive/MyDrive/Colab Notebooks/sign-language-interpretation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 13:57:46.763791: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-27 13:57:47.418462: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-27 13:57:47.425106: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-27 13:57:51.960786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plotter_lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL as image_lib\n",
    "import tensorflow as tflow\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Input, Lambda ,Dense ,Flatten ,Dropout\n",
    "%matplotlib inline\n",
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13440 images belonging to 24 classes.\n",
      "Found 5759 images belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "def load_image_dataset(root_directory, image_size, batch_size, validate_size):\n",
    "    # Set the intial DataFrame map\n",
    "    # letters = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6, 'H':7, 'I':8, 'K':9, 'L':10, 'M':11, 'N':12,\n",
    "    #             'O':13, 'P':14, 'Q':15, 'R':16, 'S':17, 'T':18, 'U':19, 'V':20, 'W':21, 'X':22, 'Y':23}\n",
    "\n",
    "    # Create a data generator\n",
    "    datagen = tflow.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=validate_size)\n",
    "\n",
    "    # Generate the training dataset from directory using the data generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        root_directory,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True)\n",
    "    \n",
    "    # Generate the validation dataset from directory using the data generator\n",
    "    validate_generator = datagen.flow_from_directory(\n",
    "        root_directory,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=True)\n",
    "    \n",
    "    return train_generator, validate_generator\n",
    "\n",
    "root_directory = os.path.join(\"raw_data\", \"landmark_train_data\")  # Replace with the root directory path\n",
    "image_size = (200, 200)\n",
    "batch_size = 32\n",
    "validate_size = 0.3   # Set =0 if NO validation data output \n",
    "\n",
    "train_data, val_data = load_image_dataset(root_directory, image_size, batch_size, validate_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13440 images belonging to 24 classes.\n",
      "Found 5759 images belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "root_directory = os.path.join(\"raw_data\", \"landmark_train_data\")  # Replace with the root directory path\n",
    "image_size = (100, 100)\n",
    "batch_size = 32\n",
    "validate_size = 0.3   # Set =0 if NO validation data output \n",
    "\n",
    "train_data_100, val_data_100 = load_image_dataset(root_directory, image_size, batch_size, validate_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'A': 0,\n",
       "  'B': 1,\n",
       "  'C': 2,\n",
       "  'D': 3,\n",
       "  'E': 4,\n",
       "  'F': 5,\n",
       "  'G': 6,\n",
       "  'H': 7,\n",
       "  'I': 8,\n",
       "  'K': 9,\n",
       "  'L': 10,\n",
       "  'M': 11,\n",
       "  'N': 12,\n",
       "  'O': 13,\n",
       "  'P': 14,\n",
       "  'Q': 15,\n",
       "  'R': 16,\n",
       "  'S': 17,\n",
       "  'T': 18,\n",
       "  'U': 19,\n",
       "  'V': 20,\n",
       "  'W': 21,\n",
       "  'X': 22,\n",
       "  'Y': 23},\n",
       " {'A': 0,\n",
       "  'B': 1,\n",
       "  'C': 2,\n",
       "  'D': 3,\n",
       "  'E': 4,\n",
       "  'F': 5,\n",
       "  'G': 6,\n",
       "  'H': 7,\n",
       "  'I': 8,\n",
       "  'K': 9,\n",
       "  'L': 10,\n",
       "  'M': 11,\n",
       "  'N': 12,\n",
       "  'O': 13,\n",
       "  'P': 14,\n",
       "  'Q': 15,\n",
       "  'R': 16,\n",
       "  'S': 17,\n",
       "  'T': 18,\n",
       "  'U': 19,\n",
       "  'V': 20,\n",
       "  'W': 21,\n",
       "  'X': 22,\n",
       "  'Y': 23})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_indices,  val_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiliaze_model_vgg16(image_width, image_height, no_chans, n_classes):\n",
    "    \n",
    "    #Initialising vgg16 \n",
    "    classifier_vgg16 = VGG16(input_shape= (image_width,image_height,no_chans),include_top=False,weights='imagenet')\n",
    "    \n",
    "    #Don't train existing weights for vgg16\n",
    "    for layer in classifier_vgg16.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    #Add other layers for pre-trained model    \n",
    "    classifier = classifier_vgg16.output #head mode\n",
    "    classifier = Flatten()(classifier) #adding layer of flatten\n",
    "    classifier = Dense(units=512, activation='relu')(classifier)\n",
    "    classifier = Dense(units=256, activation='relu')(classifier)\n",
    "    classifier = Dense(units=128, activation='relu')(classifier)\n",
    "    classifier = Dropout(0.6)(classifier)\n",
    "    classifier = Dense(units=n_classes, activation='softmax')(classifier)\n",
    "\n",
    "    #Build & compile the model\n",
    "    model = Model(inputs =classifier_vgg16.input, outputs = classifier)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_devices = tflow.config.list_physical_devices('GPU')\n",
    "gpu_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier_vgg16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classifier_vgg16\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier_vgg16' is not defined"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model_vgg16_100 = initiliaze_model_vgg16(100, 100, 3, 24)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "history_vgg16_100 = model_vgg16_100.fit(\n",
    "                    train_data_100,\n",
    "                    validation_data = val_data_100,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[es],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_resn50(image_width, image_height, no_chans, n_classes):\n",
    "    #Initialising ResNet50 \n",
    "    classifier_resnet = tflow.keras.applications.ResNet50(input_shape= (image_width,image_height,no_chans),include_top=False,weights='imagenet')\n",
    "    \n",
    "    #don't train existing weights for resnet50\n",
    "    for layer in classifier_resnet.layers:\n",
    "        layer.trainable = False\n",
    "     \n",
    "    #Add the necessary layers for pre-trained model   \n",
    "    classifier = classifier_resnet.output #head mode\n",
    "    classifier = Flatten()(classifier) #adding layer of flatten\n",
    "    classifier = Dense(units=512, activation='relu')(classifier)\n",
    "    classifier = Dense(units=256, activation='relu')(classifier)\n",
    "    classifier = Dense(units=128, activation='relu')(classifier)\n",
    "    classifier = Dropout(0.2)(classifier)\n",
    "    classifier = Dense(units=n_classes, activation='softmax')(classifier)\n",
    "\n",
    "    #Build and compile the model\n",
    "    model = Model(inputs = classifier_resnet.input , outputs = classifier)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model_resn50_100 = initialize_model_resn50(100, 100, 3, 24)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "history_resn50_200 = model_resn50_100.fit(\n",
    "                    train_data_100,\n",
    "                    validation_data = val_data_100,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[es],\n",
    "                    verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sign-language-interpretation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
